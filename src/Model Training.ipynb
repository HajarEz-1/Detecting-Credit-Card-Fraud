{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9cf399e6",
   "metadata": {},
   "source": [
    "# Model Training Notebook\n",
    "This notebook implements a machine learning pipeline for training multiple classification models on a downsampled dataset. The workflow includes loading preprocessed data and training several different classifier models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24c60267",
   "metadata": {},
   "source": [
    "## Data Loading Section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d7866cca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "# Load the training data\n",
    "X_train_downsampled = joblib.load('../Data/X_train_downsampled.joblib')\n",
    "y_train_downsampled = joblib.load('../Data/y_train_downsampled.joblib')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cb4850c",
   "metadata": {},
   "source": [
    "## The code initializes five different classification models:\n",
    "\n",
    "### Random Forest Classifier\n",
    "\n",
    "Ensemble learning method using multiple decision trees\n",
    "Good for handling non-linear relationships\n",
    "\n",
    "\n",
    "### Support Vector Machine (SVM)\n",
    "\n",
    "Effective for high-dimensional spaces\n",
    "Works well when clear margin of separation exists\n",
    "\n",
    "\n",
    "### K-Nearest Neighbors (KNN)\n",
    "\n",
    "Instance-based learning\n",
    "Simple but effective for many classification tasks\n",
    "\n",
    "\n",
    "### Logistic Regression\n",
    "\n",
    "Linear classifier with probabilistic approach\n",
    "Good baseline model for binary classification\n",
    "\n",
    "\n",
    "### Gradient Boosting Classifier\n",
    "\n",
    "Advanced ensemble method\n",
    "Often provides high accuracy but may require tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0defd3a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForest model trained and saved.\n",
      "SVM model trained and saved.\n",
      "KNN model trained and saved.\n",
      "LogisticRegression model trained and saved.\n",
      "GradientBoosting model trained and saved.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import joblib\n",
    "\n",
    "# Initialize models\n",
    "models = {\n",
    "    \"RandomForest\": RandomForestClassifier(random_state=42),\n",
    "    \"SVM\": SVC(random_state=42),\n",
    "    \"KNN\": KNeighborsClassifier(),\n",
    "    \"LogisticRegression\": LogisticRegression(random_state=42),\n",
    "    \"GradientBoosting\": GradientBoostingClassifier(random_state=42)\n",
    "}\n",
    "\n",
    "# Train each model on the downsampled training data and save them to the Models directory\n",
    "for model_name, model in models.items():\n",
    "    # Fit the model\n",
    "    model.fit(X_train_downsampled, y_train_downsampled)\n",
    "    \n",
    "    # Save the model using joblib\n",
    "    joblib.dump(model, f'../Models/{model_name}_model.joblib')\n",
    "    print(f\"{model_name} model trained and saved.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeb8b5c6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
